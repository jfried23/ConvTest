{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>File Parser</h3>\n",
    "<p>My function for injesting the Netflix dataset text files:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob('/Users/frjo6001/Desktop/netflix-prize-data/combined_*.txt')\n",
    "\n",
    "def netflixDataParse( file_path ):\n",
    "    movieExt = re.compile('(\\d+)\\:\\n')\n",
    "    dataExt  = re.compile('(\\d+),(\\d+),(\\d{4}\\-\\d{2}-\\d{2})')\n",
    "    \n",
    "    last_movie = None\n",
    "    data=[]\n",
    "    for line in open(file_path).readlines():\n",
    "        movie = movieExt.findall(line)\n",
    "        review= dataExt.findall(line)\n",
    "        if len(movie) > 0: last_movie = int(movie[0])\n",
    "        elif len(review) > 0:\n",
    "            review = review[0]\n",
    "            data.append((int(review[0]), last_movie, int(review[1]), review[2]))\n",
    "    \n",
    "    return pd.DataFrame(data=data, columns=['userID', 'movieID', 'rating','date'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 58s, sys: 18 s, total: 2min 16s\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%time d=netflixDataParse(files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works, but text file i/o is slow. We can spead this up by going to a binary file format!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/frjo6001/Desktop/netflix-prize-data/combined_data_1.txt',\n",
       " '/Users/frjo6001/Desktop/netflix-prize-data/combined_data_2.txt',\n",
       " '/Users/frjo6001/Desktop/netflix-prize-data/combined_data_3.txt',\n",
       " '/Users/frjo6001/Desktop/netflix-prize-data/combined_data_4.txt']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "p='/Users/frjo6001/Desktop/netflix-prize-data/data_bin/{0}_data/df_{0}_{1}.pkl'\n",
    "\n",
    "for i,f in enumerate(sorted(files)):\n",
    "    d = netflixDataParse(f).astype({'rating':np.uint8, \n",
    "                                    'userID':np.uint32, \n",
    "                                    'movieID':np.uint32}\n",
    "    indx = np.arange(d.shape[0])\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(indx)\n",
    "    point = round(indx.shape[0]*.8)\n",
    "    \n",
    "    df_train, df_test = d.iloc[0:point], d.iloc[point:]\n",
    "    df_train.to_pickle(p.format('train',i),compression='bz2')\n",
    "    df_test.to_pickle(p.format('test',i),compression='bz2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Pytorch Dataloader ABC</h3>\n",
    "<p>To use PyTorch built in tools for data loading we need to implement our own \"\\__len__\" and \"\\__getitem__\" methods. See doccumentation in torch.utils.data.dataset.Dataset\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "class NetflixDS( torch.utils.data.dataset.Dataset ):\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        self.path = path\n",
    "        self.df   = None\n",
    "    \n",
    "    def load(self): \n",
    "        d = pd.read_pickle(self.path, compression='bz2')\n",
    "        self.df = d[['userID','movieID','rating']]\n",
    "        self.df = self.df.astype({'rating':np.uint8, \n",
    "                                  'userID':np.uint32, \n",
    "                                  'movieID':np.uint32}\n",
    "                                )\n",
    "    def clear(self):\n",
    "        del self.df\n",
    "        self.df = None\n",
    "        \n",
    "    def __len__(self):\n",
    "        if not isinstance(self.df, pd.DataFrame ):\n",
    "            self.load()\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if not isinstance(self.df, pd.DataFrame ):\n",
    "            self.load()          \n",
    "        return self.df.iloc[index].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_file_paths = glob.glob('/Users/frjo6001/Desktop/netflix-prize-data/data_bin/train_data/*.pkl')\n",
    "df = torch.utils.data.ConcatDataset([NetflixDS(d) for d in bin_file_paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users  = set()\n",
    "unique_movies = set()\n",
    "\n",
    "for ds in df.datasets:\n",
    "    unique_users = unique_users.union( set(ds.df.userID.unique()) )\n",
    "    unique_movies = unique_movies.union( set(ds.df.movieID.unique()) )\n",
    "    \n",
    "unique_users = {u:i for i,u in enumerate(unique_users)}\n",
    "unique_movies = {u:i for i,u in enumerate(unique_movies)}\n",
    "\n",
    "for ds in df.datasets:\n",
    "    ds.df.userID = ds.df.userID.apply(lambda x: unique_users[x])\n",
    "    ds.df.movieID = ds.df.movieID.apply(lambda x: unique_movies[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoader = torch.utils.data.DataLoader(df, batch_size=500, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetflixRecom(torch.nn.Module):\n",
    "    def __init__(self, unique_users, unique_movies):\n",
    "        super().__init__()\n",
    "        self.userEmbed  = torch.nn.Embedding(len(unique_users)+1,8)\n",
    "        self.movieEmbed = torch.nn.Embedding(len(unique_movies)+1,8)\n",
    "        \n",
    "        self.batch_norm = torch.nn.BatchNorm1d(1)\n",
    "    \n",
    "    def forward(self,**b):\n",
    "        e_u = self.userEmbed(b['userID'].view(-1,1))\n",
    "        e_m = self.movieEmbed(b['movieID'].view(-1,1))\n",
    "        \n",
    "        p = self.batch_norm(torch.matmul( e_u, e_m.transpose(1,2)))\n",
    "        \n",
    "        return p\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMod = NetflixRecom(unique_users, unique_movies)\n",
    "opt   = torch.optim.SGD(myMod.parameters(),lr=1.e-3)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c707d74cd4e742a9aa1cf4915cef7eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=160769), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 of 160769: 12.29\n",
      "Step 10001 of 160769: 1.51\n",
      "Step 20001 of 160769: 1.35\n",
      "Step 30001 of 160769: 1.27\n",
      "Step 40001 of 160769: 1.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-63:\n",
      "Process Process-64:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-0e803f3dfdde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Step {} of {}: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetloss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmyMod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshare_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/utils/data/dataset.py\", line 81, in __getitem__\n",
      "    return self.datasets[dataset_idx][sample_idx]\n",
      "  File \"<ipython-input-108-e0fcb1636d31>\", line 27, in __getitem__\n",
      "    return self.df.iloc[index].to_dict()\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1478, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/core/indexing.py\", line 2085, in _getitem_axis\n",
      "    if com.is_bool_indexer(key):\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/core/common.py\", line 101, in is_bool_indexer\n",
      "    if isinstance(key, (ABCSeries, np.ndarray, ABCIndex)):\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/core/dtypes/generic.py\", line 9, in _check\n",
      "    return getattr(inst, attr, '_typ') in comp\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/torch/utils/data/dataset.py\", line 81, in __getitem__\n",
      "    return self.datasets[dataset_idx][sample_idx]\n",
      "  File \"<ipython-input-108-e0fcb1636d31>\", line 27, in __getitem__\n",
      "    return self.df.iloc[index].to_dict()\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/core/indexing.py\", line 1478, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/core/indexing.py\", line 2104, in _getitem_axis\n",
      "    return self._get_loc(key, axis=axis)\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/core/indexing.py\", line 145, in _get_loc\n",
      "    return self.obj._ixs(key, axis=axis)\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/core/frame.py\", line 2626, in _ixs\n",
      "    dtype=new_values.dtype)\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/core/series.py\", line 281, in __init__\n",
      "    self.name = name\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/core/generic.py\", line 4388, in __setattr__\n",
      "    object.__getattribute__(self, name)\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/core/series.py\", line 403, in name\n",
      "    return self._name\n",
      "  File \"/Users/frjo6001/.pyenv/versions/3.6.5/lib/python3.6/site-packages/pandas/core/generic.py\", line 4362, in __getattr__\n",
      "    def __getattr__(self, name):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "netloss = 0\n",
    "for i, b in enumerate(tqdm.tqdm_notebook(dataLoader)):\n",
    "    preds = myMod(**b)\n",
    "    loss = loss_fn(preds.view(-1,1),b['rating'].unsqueeze(-1).float())\n",
    "    loss.backward()\n",
    "    netloss += loss.item()\n",
    "    if i%10000==0: print(\"Step {} of {}: {}\".format(i+1,len(dataLoader), round(netloss/(i+1),2)))\n",
    "    opt.step()\n",
    "    myMod.zero_grad()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-9162721bd984>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "torch.cud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
